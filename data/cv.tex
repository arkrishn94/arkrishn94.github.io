\documentclass[10pt,letterpaper,sans]{moderncv}

%--------------------------------------------------
% ModernCV setup
%--------------------------------------------------
\moderncvstyle{banking}       % styles: casual, classic, oldstyle, banking, fancy
\moderncvcolor{blue}          % colors: blue, orange, green, red, purple, grey, black

% Adjust page layout
\usepackage[scale=0.87]{geometry}
\setlength{\hintscolumnwidth}{2.7cm}  % width of date column

% Tighter bullet spacing
\usepackage{enumitem}
\setlist[itemize]{leftmargin=*, itemsep=1pt, topsep=1pt}

% Encoding
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

%--------------------------------------------------
% Personal data
%--------------------------------------------------
\name{Aditya}{Krishnan}
\email{aditya.krishnan94@gmail.com}
\phone[mobile]{+1 412-623-9519}
\social[linkedin]{arkrishn}
\social[googlescholar]{Google Scholar} % label hack; can replace with custom symbol if desired



% \title{Curriculum Vitae} % optional

\begin{document}
\makecvtitle

%--------------------------------------------------
% Research Interests
%--------------------------------------------------
\section{Research Interests}
Similarity search, retrieval augmented generation, scalable machine learning, information retrieval.

%--------------------------------------------------
% Professional Experience
%--------------------------------------------------
\section{Professional Experience}

% ---------------- MICROSOFT ----------------
\cventry
  {Senior Software Engineer}
  {Remote}
  {Microsoft}
  {Mar 2025 -- Present}
  {}
  {
    \begin{itemize}
      \item Leading design and implementation of core vector indexing algorithms for M365 Copilot within Microsoft Substrate.
    \end{itemize}
  }

% ---------------- PINECONE SENIOR RS ----------------
\cventry
  {Senior Research Scientist}
  {New York City}
  {Pinecone Systems}
  {Jan 2024 -- Oct 2024}
  {}
  {
    \begin{itemize}
      \item Led research on vector quantization for Pinecone Serverless using SIMD-optimized Rust kernels, achieving a 2$\times$ improvement in cached data utilization.
      \item Implemented a new negative sampling method for text cross-encoders, improving document retrieval accuracy and surpassing industry rerankers (e.g., Cohere-Rerank-V3).
    \end{itemize}
  }

% ---------------- PINECONE RS ----------------
\cventry
  {Research Scientist}
  {}
  {}
  {Oct 2022 -- Jan 2024}
  {}
  {
    \begin{itemize}
      \item Designed Pineconeâ€™s winning solution for the NeurIPS 2023 Big ANN Challenge (Out-of-Distribution track): Rust system achieving 35K+ QPS on a 10M-sized index using 8 vCPUs and 16 GB RAM.
      \item Developed a novel query-routing mechanism for IVF-style vector indexes (published in NeurIPS 2025), reducing scanned data by 25\% vs.\ Google ScaNN algorithm.
    \end{itemize}
  }

% ---------------- PINECONE INTERN ----------------
\cventry
  {Science Intern}
  {Remote}
  {Pinecone Systems}
  {May 2021 -- Aug 2021}
  {}
  {
    \begin{itemize}
      \item Researched quantization techniques for similarity search under Edo Liberty (CEO and Founder).
    \end{itemize}
  }


%--------------------------------------------------
% Education
%--------------------------------------------------
\section{Education}

\cventry
  {Ph.D.\ in Computer Science}
  {Baltimore, MD}
  {Johns Hopkins University, Whiting School of Engineering}
  {Sep 2018 -- Sep 2022}
  {}
  {
    Advisor: Vladimir Braverman\\
    Thesis: \emph{Fast and Memory-Efficient Algorithms for Matrix Spectrum Approximation}
  }

\cventry
  {M.S.\ in Computer Science}
  {Pittsburgh, PA}
  {Carnegie Mellon University, School of Computer Science}
  {May 2017 -- May 2018}
  {}
  {
    Advisor: Anupam Gupta\\
    Thesis: \emph{Pricing Online Metric Matching Algorithms on Trees}
  }

\cventry
  {B.S.\ in Computer Science (Minor: Engineering Studies)}
  {Pittsburgh, PA}
  {Carnegie Mellon University, School of Computer Science}
  {Aug 2013 -- May 2017}
  {}
  {}

%--------------------------------------------------
% Honors and Awards
%--------------------------------------------------
\section{Honors and Awards}

\cvitem{2022}{JHU MINDS TRIPODS Data Science Fellowship (awarded to $\sim$5 students across two schools per cycle).}
\cvitem{2022}{NeurIPS Top Reviewer (less than 10\% of reviewers).}
\cvitem{2018}{JHU Computer Science Department Fellowship (awarded to 2 students in an incoming class of 50+).}

%--------------------------------------------------
% Technical Skills
%--------------------------------------------------
\section{Technical Skills}

\cvitem{Languages}{Rust; Python.}
\cvitem{Libraries}{PyTorch; Distributed Data Parallel; FSDP; SciKit-learn.}

%--------------------------------------------------
% Publications
%--------------------------------------------------
\section{Publications}
\cvitem{}{Authors appear in alphabetical order. * denotes equal contribution.}

\cvitem{NeurIPS 2025}
  {Optimistic Query Routing for Maximum Inner-Product Search. With Sebastian Bruch and Franco Maria Nardini.}

\cvitem{ICALP 2023}
  {Lower Bounds for Pseudo-Deterministic Counting in a Stream. With Vladimir Braverman, Robert Krauthgamer, and Shay Sapir.}

\cvitem{STOC 2022}
  {Sublinear Time Spectral Density Estimation. With Vladimir Braverman and Christopher Musco.}

\cvitem{ACML 2021}
  {Lifelong Learning with Sketched Structural Regularization. With Haoran Li, Jingfeng Wu*, Soheil Kolouri*, Praveen K.\ Pilly, and Vladimir Braverman.}

\cvitem{COLT 2021}
  {Near-Optimal Entrywise Sampling of Numerically Sparse Matrices. With Vladimir Braverman, Robert Krauthgamer, and Shay Sapir.}

\cvitem{ICML 2020}
  {Schatten Norms in Matrix Streams: Hello Sparsity, Goodbye Dimension. With Vladimir Braverman, Robert Krauthgamer, and Roi Sinoff.}

\cvitem{WINE 2020}
  {Competitively Pricing Parking in a Tree. With Max Bender, Jacob Gilbert, and Kirk Pruhs.}

\cvitem{APPROX 2018}
  {On Sketching the $q$ to $p$ Norms. With Sidhanth Mohanty and David P.\ Woodruff.}



%--------------------------------------------------
% Talks
%--------------------------------------------------
\section{Talks}

\cvitem{2022}{Sublinear Time Spectral Density Estimation, STOC, Rome, Italy.}
\cvitem{2018}{Sublinear Time Spectral Density Estimation, JHU CS Theory Seminar, Baltimore.}
\cvitem{2020}{Schatten Norms in Matrix Streams: The Role of Sparsity, ICML.}
\cvitem{2019}{Schatten Norms in Matrix Streams: The Role of Sparsity, JHU CS Theory Seminar, Baltimore.}
\cvitem{2018}{Pricing Online Metric Matching Algorithms on Trees, CMU Theory Seminar, Pittsburgh.}

%--------------------------------------------------
% Academic Service
%--------------------------------------------------
\section{Academic Service}

\cvitem{Reviewer}
  {NeurIPS 2021--2024; ICML 2021--2024; ICLR 2022--2024; STOC 2021--2022; SODA 2021; PODS 2020.}

\cvitem{Seminar Organizer}
  {JHU Theory Seminar (2021, 2022).}

\cvitem{Teaching Assistant}
  {Introduction to Algorithms (Fall 2019, Spring 2020, Spring 2022); Approximation Algorithms (Spring 2021).}

%--------------------------------------------------
% References
%--------------------------------------------------
\section{References}

\cvitem{}{Edo Liberty, CEO and Founder, Pinecone --- \texttt{edo@edoliberty.com}}
\cvitem{}{Christopher Musco, Assistant Professor, New York University --- \texttt{cmusco@nyu.edu}}
\cvitem{}{Vladimir Braverman, Professor, Rice University --- \texttt{vb21@rice.edu}}

\end{document}
